## Задание 2. Реализация нейронной сети для детекции объектов CenterNet.

### Описание
В этом задании вам необходимо реализовать на torch упрощенную версию сети CenterNet, статья [Objects as Points](https://arxiv.org/pdf/1904.07850.pdf).
Аналогично первому заданию, имеется пакет-заготовка для реализации сети. Ваша задача - разобраться в статье и реализовать те фрагменты, где в коде встречается
 `raise NotImplementedError` (а также `pass #NotImplemented`).

Замечания:
- изучение кода [оригинальной](https://github.com/xingyizhou/CenterNet) CenterNet приветствуется.
- не перепутайте с другой статьей [CenterNet: Keypoint Triplets for Object Detection](https://arxiv.org/abs/1904.08189): она сложнее!

### Оценка
Оценка ставится инструкторами вручную, с проверкой реализации компонентов и результатов тренировки.
В срок [10.10 – 31.10], `максимум баллов за задание` = 20. Начиная с 31.10, `максимум баллов за задание` = 10. Начиная с 15.12, баллы не ставятся.

### Список компонентов, которые надо реализовать
- a4_course_cvdl_t2.backbone.UpscaleTwiceLayer (2 балла)
- a4_course_cvdl_t2.backbone.HeadlessResnet34 (2 балла)
- a4_course_cvdl_t2.head.CenterNetHead (2 балла)
- a4_course_cvdl_t2.loss.CenterNetLoss (2 балла)
- a4_course_cvdl_t2.convert.ObjectsToPoints (3 балла)
- a4_course_cvdl_t2.convert.PointsToObjects (4 балла)
- a4_course_cvdl_t2.network.PointsNonMaxSuppression (3 балла)

Корректность компонентов оценивается по тестам и "на глаз": если компонент не проходит почему-то тест, но по смыслу верен, он будет засчитан
Все компоненты - 18 баллов. Еще 2 балла даются за "успешную" тренировку на TinyCoco( см. ниже ).

### Баллы за тренировку на TinyCoco
Для удобства отладки приложен `task2/checks_notebook.ipynb`, в котором сначала вызываются компоненты по-отдельности, а затем выполняется тренировка на датасете TinyCoco (игрушечная)
Датасет TinyCoco приложен в task2/data, для тренировки на нем достаточно CPU.

Тренировку можно делать с pretrained бэкбоном.

Тренировка считается успешной, если лосс в логах тренировки (выводятся в checks_notebook.ipynb) стабильно понижается.

### Дополнительные баллы за тренировку на CocoText
При тренировке на TinyCoco (~10 изображений) чего-то даже отдаленно работающего не получится в любом случае - слишком мало данных. Чтобы проверить, работоспособен ли написанный вами детектор, его надо обучить на полноразмерном датасете (~10K изображений).

В ноутбуке `train_cocotext.ipynb` приведена тренировка детектора на [CocoText](https://bgshih.github.io/cocotext/) - датасете с изображениями из COCO, на которых размечен весь текст.

Вам необходимо скачать изображения [COCO](https://cocodataset.org) версии 2014 года и разметку cocotext.v2.json с сайта CocoText, прогнать обучение в ноутбуке на своей реализации CenterNet и удостовериться, что ваше детектор после обучения выдаёт что-то похожее на детекции текста.

За успешную тренировку на CocoText дополнительно начисляется 3 балла. У этого пункта дедлайн - конец семестра, т.е. получить доп. баллы за успешную тренировку работающего детектора можно и после 31.10.


========
Ревью
========
За реализацию компонент - (18 - 1) = 17 балллов, за тренировку на Coco  (2 -1) = 1 балл. 
Итог: 18 баллов

-1 балл за тренировку:
Лосс падает, но судя по предикту тренировки, сеть не оверфитнулась на микро-датасет.
В логах видно высокий лосс за heatmap, в предикты не похожи на таргеты в примере.

Предположительно, причина в ошибке в лоссе (см комменты):
```python
    def loss_fl(self, predict_cyx, target_cyx, alpha=2, beta=4):
        """
        Focal loss между двумя heatmap. В статье параметры FL alpha=2, beta=4.
        """
        #! в pos_mask попадают только максимумы гауссиан
        pos_mask = (target_cyx == 1).float()
        pos_elements = (((1 - predict_cyx) ** alpha) * torch.log(predict_cyx + 1e-8)) * pos_mask

        #! сюда попадают только локации, далекие от центра пика - т.к. рядом с пиком
        #! из-за сглаживания гауссианой 0 < target_cyx < 1
        neg_mask = (target_cyx == 0).float()
        #! Более корректно было бы `neg_mask = 1 - pos_mask`
        neg_elements = (((1 - target_cyx) ** beta) * (predict_cyx ** alpha) \
                            * torch.log(1 - predict_cyx + 1e-8)) * neg_mask

        loss = -torch.sum(pos_elements + neg_elements)
```
Часть локаций heatmap с `0 < target_cyx < 1` не попадает ни в позитивные, ни в негативные элементы - получаются как бы one-hot маски в таргете в лоссе.

Заметки (не влияет на баллы):
- авторы используют не smooth-L1 для регрессии, а L1 - в статье указано, что L1 даёт хуже результат.
- реализация ResNet здорово напоминает код из torchvision

